{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories from numeric values\n",
    "\n",
    "We often have a column with many numeric values and we want to group them to bins or buckets, such as age groups or value tiers. In Excel we can do it using: \n",
    "\n",
    "- Data Menu -> Data Analysis -> Histogram or Rank and Percentile\n",
    "- _VLOOKUP_ (`=LOOKUP(A1,{0,7,14,31,90,180,360},{\"0-6\",\"7-13\",\"14-30\",\"31-89\",\"90-179\",\"180-359\",\">360\"})`, for example), or \n",
    "- _IF_ (`=if(b2>30,\"large\",if(A1>20,\"medium\",if(A1>=10,\"small\",if(A1<10,\"tiny\",\"\"))))`, for example)\n",
    "- _INDEX_ (`=INDEX({\"Small\",\"Medium\",\"Large\"},LARGE(IF(A1>{0,11,21},{1,2,3}),1))`, for example)\n",
    "\n",
    "\n",
    "[![Open In Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/aiola-lab/from-excel-to-pandas/blob/master/notebooks/02.08_group_values.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut Function\n",
    "\n",
    "Since this is a common need, Pandas has built-in functions _cut_ and _qcut_ that make it more flexible and accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real life example\n",
    "\n",
    "### Loading Data\n",
    "\n",
    "As usual, let's load a dataset to work on. We will use the dataset that is used before, \"Bike Share\". This is a data set about the demand of bike share service in Seoul. Please note that we need to modify the default encoding of _read_csv_ from 'UTF-8' to 'latin1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_share_data = (\n",
    "    pd\n",
    "    .read_csv(\n",
    "        'https://archive.ics.uci.edu/ml/machine-learning-databases/00560/SeoulBikeData.csv', \n",
    "        encoding='latin1'\n",
    "    )\n",
    ")\n",
    "bike_share_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Data Visulizations\n",
    "\n",
    "* Start with the table above\n",
    "* Create Histograms for numeric columns\n",
    "* Plot the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bike_share_data\n",
    "    [['Rented Bike Count']]\n",
    "    .plot(\n",
    "        kind='hist', \n",
    "        alpha=0.5, \n",
    "        title='Rented Bike Count'\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bike_share_data\n",
    "    [['Temperature(°C)']]\n",
    "    .plot(\n",
    "        kind='hist', \n",
    "        alpha=0.5, \n",
    "        title='Temperature(°C)'\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating bins with _Cut_\n",
    "\n",
    "* Start with the table above\n",
    "* Focus on the temperature column\n",
    "* Create 5 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd\n",
    "    .cut(\n",
    "        bike_share_data\n",
    "        ['Temperature(°C)'], \n",
    "        5\n",
    "    )  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the interval fo each of the bins:\n",
    "`[(-17.857, -6.36] < (-6.36, 5.08] < (5.08, 16.52] < (16.52, 27.96] < (27.96, 39.4]]` that are in order and split to more or less equal sizes from temperature values perspective. Let's see how well they split the data:\n",
    "\n",
    "* Split the temperature value into 5 bins\n",
    "* Count the number of records in each bin\n",
    "* Sort the values by the temperature range (the index of the series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd\n",
    "    .cut(\n",
    "        bike_share_data\n",
    "        ['Temperature(°C)'], \n",
    "        5\n",
    "    )\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we see that the bins are in order when we sort them, and not by alphabetic order. More importanty, we see that they are not equal in size of records, and not based on any other meaningful split.\n",
    "\n",
    "### Setting the bins' limits\n",
    "\n",
    "We can set the bins to be more meaningful by setting the limits explicitly. As experts in bicycles, we might know the temperature ranges that are suitable for different accessories and clothings. Let's fix the ranges based on this domain knowledge:\n",
    "\n",
    "* Split the temperature value into 5 bins based on bicycle professional ranges\n",
    "* Count the number of records in each bin\n",
    "* Sort the values by the temperature range (the index of the series)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd\n",
    "    .cut(\n",
    "        bike_share_data\n",
    "        ['Temperature(°C)'], \n",
    "        bins=[-18, 0, 8, 16, 24, 40]\n",
    "    )\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding meaningful labels\n",
    "\n",
    "* Create a new column in the table for the temperature ranges\n",
    "* Split the temperature value into 5 bins based on bicycle professional ranges\n",
    "* Count the number of records in each bin\n",
    "* Add human readable labels to the bins\n",
    "* Sort the values by the temperature range (the index of the series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_share_data['Temperature Range'] = (\n",
    "    pd\n",
    "    .cut(\n",
    "        bike_share_data\n",
    "        ['Temperature(°C)'], \n",
    "        bins=[-18, 0, 8, 16, 24, 40],\n",
    "        labels=['Below Freezing', 'Freezing', 'Cold', 'Warm','Sizzling']\n",
    "    )\n",
    "    \n",
    ")\n",
    "(\n",
    "    bike_share_data\n",
    "    ['Temperature Range']\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the order is still the right order and not alphabetical, and the split is more balanced in the number of records.\n",
    "\n",
    "### Boxplot for each bin\n",
    "\n",
    "Now we can take every group of records and calculate and plot their box-plot showing the mean and the different quantiles of the different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bike_share_data\n",
    "    [['Rented Bike Count','Temperature Range']]\n",
    "    .boxplot(by='Temperature Range')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is wrong with Historgram\n",
    "\n",
    "As much as historgrams are popular and simple to plot, they have many limitation:\n",
    "- It depends (too much) on the number of bins.\n",
    "- It depends (too much) on variable’s maximum and minimum.\n",
    "- It doesn’t allow to detect relevant values.\n",
    "- It doesn’t allow to discern continuous from discrete variables.\n",
    "- It makes it hard to compare distributions.\n",
    "\n",
    "We will use a couple of other plot option to see the data distributions more accurately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Density Estimator (KDE)\n",
    "\n",
    "This method is calculating and plotting the estimation of the data distribution, and it is part of the Pandas built-in functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bike_share_data\n",
    "    ['Rented Bike Count']\n",
    "    .plot\n",
    "    .kde(\n",
    "        title='Rented Bike Count',\n",
    "        grid=True\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bike_share_data\n",
    "    ['Temperature(°C)']\n",
    "    .plot\n",
    "    .kde(\n",
    "        title='Temperature(°C)', \n",
    "        grid=True\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Distribution Function (CDF)\n",
    "\n",
    "The second option is using counts of the different percentiles of the data and using a cumulative plot makes it easy to find the value of each percentile and calculate the percentage of data points between every given percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecdf = ECDF(bike_share_data['Temperature(°C)'])\n",
    "plt.plot(ecdf.x, ecdf.y)\n",
    "plt.grid(True)\n",
    "plt.title('Temperature(°C)'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecdf = ECDF(bike_share_data['Rented Bike Count'])\n",
    "plt.plot(ecdf.x, ecdf.y)\n",
    "plt.grid(True)\n",
    "plt.title('Rented Bike Count'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by Quantiles using _qcut_\n",
    "\n",
    "When using a target score such as grades or number of rentals, it makes sense to use the split using the Quantiles of the scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_share_data['Usage Level'] = (\n",
    "    pd\n",
    "    .qcut(\n",
    "        bike_share_data['Rented Bike Count'], \n",
    "        q=4,\n",
    "        labels=['Low', 'Medium', 'High', 'Very High']\n",
    "    )\n",
    ")\n",
    "(\n",
    "    bike_share_data\n",
    "    ['Usage Level']\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bike_share_data\n",
    "    [['Temperature(°C)','Usage Level']]\n",
    "    .boxplot(by='Usage Level')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat map with the new value group\n",
    "\n",
    "Now that we have the new value categories and we can create heat map to see the hours of the day that are the peak hours that can be used with higher price tiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    bike_share_data\n",
    "    [['Usage Level','Hour','Date']]\n",
    "    .pivot_table(\n",
    "        index='Hour', \n",
    "        columns='Usage Level',\n",
    "        aggfunc='count'\n",
    "    )\n",
    "    .droplevel(0, axis='columns'),\n",
    "    cmap=\"YlOrRd\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
